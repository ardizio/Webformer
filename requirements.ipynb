{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Paper Requirements\n",
    "\n",
    "The requirements are inside `requirements.txt`, and are related to the WebFormer 2022 paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppr_v_datasets=\"1.1.3\"\n",
    "ppr_v_numpy=\"1.19.2\"\n",
    "ppr_v_pandas=\"1.1.5\"\n",
    "ppr_v_pytorch=\"1.6\"\n",
    "ppr_v_pytrec_eval=\"0.5\"\n",
    "ppr_v_requests=\"2.25.1\"\n",
    "ppr_v_scipy=\"1.5.4\"\n",
    "ppr_v_tqdm=\"4.64.1\"\n",
    "ppr_v_transformers=\"4.2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets [PASSED]\n",
      "installed 2.15.0 [required 1.1.3]\n",
      "\n",
      "numpy [PASSED]\n",
      "installed 1.26.2 [required 1.19.2]\n",
      "\n",
      "pandas [PASSED]\n",
      "installed 2.0.3 [required 1.1.5]\n",
      "\n",
      "torch [PASSED]\n",
      "installed 2.1.1+cu121 [required 1.6]\n",
      "\n",
      "requests [PASSED]\n",
      "installed 2.31.0 [required 2.25.1]\n",
      "\n",
      "scipy [PASSED]\n",
      "installed 1.11.1 [required 1.5.4]\n",
      "\n",
      "tqdm [PASSED]\n",
      "installed 4.66.1 [required 4.64.1]\n",
      "\n",
      "transformers [PASSED]\n",
      "installed 4.36.0.dev0 [required 4.2.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import numpy\n",
    "import pandas\n",
    "import torch\n",
    "# import pytrec_eval\n",
    "import requests\n",
    "import scipy\n",
    "import tqdm\n",
    "import transformers\n",
    "from packaging import version  # Import version from the packaging module\n",
    "\n",
    "def check_version(package_name, installed_version, required_version):\n",
    "    installed = version.parse(installed_version)\n",
    "    required = version.parse(required_version)\n",
    "\n",
    "    if installed >= required:\n",
    "        print(f'{package_name} [PASSED]\\ninstalled {installed} [required {required}]\\n')\n",
    "    else:\n",
    "        print(f'[OUTDATED] {package_name}\\niinstalled {installed} [required {required}]\\n')\n",
    "\n",
    "\n",
    "check_version('datasets', datasets.__version__, ppr_v_datasets)\n",
    "check_version('numpy', numpy.__version__, ppr_v_numpy)\n",
    "check_version('pandas', pandas.__version__, ppr_v_pandas)\n",
    "check_version('torch', torch.__version__, ppr_v_pytorch)\n",
    "# check_version('pytrec_eval', pytrec_eval.__version__, ppr_v_pytrec_eval)\n",
    "check_version('requests', requests.__version__, ppr_v_requests)\n",
    "check_version('scipy', scipy.__version__, ppr_v_scipy)\n",
    "check_version('tqdm', tqdm.__version__, ppr_v_tqdm)\n",
    "check_version('transformers', transformers.__version__, ppr_v_transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download BERT_base_uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# Model name from Hugging Face model hub\n",
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "# Output folder\n",
    "output_folder = \"./bert_base_uncased\"\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "import os\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Download and save the model\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(output_folder)\n",
    "tokenizer.save_pretrained(output_folder)\n",
    "\n",
    "print(f\"Model '{model_name}' downloaded & saved to '{output_folder}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'Preprocess/data/endata' already exists.\n",
      "Directory 'Preprocess/data/endata_new_clean' already exists.\n",
      "Directory 'Preprocess/data/training_data' already exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def create_directories():\n",
    "    directories_to_create = [\n",
    "        \"Preprocess/data/endata\",\n",
    "        \"Preprocess/data/endata_new_clean\",\n",
    "        \"Preprocess/data/training_data\"\n",
    "    ]\n",
    "\n",
    "    for directory in directories_to_create:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "            print(f\"Directory '{directory}' created.\")\n",
    "        else:\n",
    "            print(f\"Directory '{directory}' already exists.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_directories()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

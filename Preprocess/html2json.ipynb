{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python has a recursion limit of 3K.\n",
    "# We raise it up to 10K\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_RAW_DATA_PATH = './data/endata/'\n",
    "DIR_CLEAN_DATA = './data/endata_new_clean/'\n",
    "JSON_TRAIN_CORPUS = './data/wiki_html_all.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 57.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto-aol(2000)\n",
      "auto-autobytel(2000)\n",
      "auto-automotive(1999)\n",
      "auto-autoweb(2000)\n",
      "auto-carquotes(2000)\n",
      "auto-cars(657)\n",
      "auto-kbb(2000)\n",
      "auto-motortrend(1267)\n",
      "auto-msn(2000)\n",
      "auto-yahoo(2000)\n",
      "book-abebooks(2000)\n",
      "book-amazon(2000)\n",
      "book-barnesandnoble(2000)\n",
      "book-bookdepository(2000)\n",
      "book-booksamillion(2000)\n",
      "book-borders(2000)\n",
      "book-buy(2000)\n",
      "book-christianbook(2000)\n",
      "book-deepdiscount(2000)\n",
      "book-waterstones(2000)\n",
      "camera-amazon(1767)\n",
      "camera-beachaudio(247)\n",
      "camera-buy(500)\n",
      "camera-compsource(430)\n",
      "camera-ecost(923)\n",
      "camera-jr(367)\n",
      "camera-newegg(220)\n",
      "camera-onsale(261)\n",
      "camera-pcnation(234)\n",
      "camera-thenerds(309)\n",
      "job-careerbuilder(2000)\n",
      "job-dice(2000)\n",
      "job-hotjobs(2000)\n",
      "job-job(2000)\n",
      "job-jobcircle(2000)\n",
      "job-jobtarget(2000)\n",
      "job-monster(2000)\n",
      "job-nettemps(2000)\n",
      "job-rightitjobs(2000)\n",
      "job-techcentric(2000)\n",
      "movie-allmovie(2000)\n",
      "movie-amctv(2000)\n",
      "movie-boxofficemojo(2000)\n",
      "movie-hollywood(2000)\n",
      "movie-iheartmovies(2000)\n",
      "movie-imdb(2000)\n",
      "movie-metacritic(2000)\n",
      "movie-msn(2000)\n",
      "movie-rottentomatoes(2000)\n",
      "movie-yahoo(2000)\n",
      "nbaplayer-espn(434)\n",
      "nbaplayer-fanhouse(446)\n",
      "nbaplayer-foxsports(425)\n",
      "nbaplayer-msnca(434)\n",
      "nbaplayer-nba(434)\n",
      "nbaplayer-si(515)\n",
      "nbaplayer-slam(423)\n",
      "nbaplayer-usatoday(436)\n",
      "nbaplayer-wiki(420)\n",
      "nbaplayer-yahoo(438)\n",
      "restaurant-fodors(2000)\n",
      "restaurant-frommers(2000)\n",
      "restaurant-gayot(2000)\n",
      "restaurant-opentable(2000)\n",
      "restaurant-pickarestaurant(2000)\n",
      "restaurant-restaurantica(2000)\n",
      "restaurant-tripadvisor(2000)\n",
      "restaurant-urbanspoon(2000)\n",
      "restaurant-usdiners(2000)\n",
      "restaurant-zagat(2000)\n",
      "university-collegeboard(2000)\n",
      "university-collegenavigator(2000)\n",
      "university-collegeprowler(2000)\n",
      "university-collegetoolkit(2000)\n",
      "university-ecampustours(1063)\n",
      "university-embark(2000)\n",
      "university-matchcollege(2000)\n",
      "university-princetonreview(615)\n",
      "university-studentaid(2000)\n",
      "university-usnews(1027)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 487.88it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 275.71it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1432.33it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 488.78it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 253.73it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 1670.44it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 358.11it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 466.10it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Open Train Corpus file\n",
    "with open(JSON_TRAIN_CORPUS,'w')as g:\n",
    "    # foreach \n",
    "    for root, dirs, files in os.walk(DIR_RAW_DATA_PATH):\n",
    "        #print(root)\n",
    "        #print(dirs)\n",
    "        #print(files)\n",
    "        #print('')\n",
    "        for dir in tqdm(dirs):\n",
    "            sub_DIR_RAW_DATA_PATH = os.path.join(root,dir)\n",
    "            # To check wich folder is working\n",
    "            #print(sub_DIR_RAW_DATA_PATH)\n",
    "            j=0\n",
    "            for sub_root,sub_dirs,sub_files in os.walk(sub_DIR_RAW_DATA_PATH):\n",
    "                if j >0:\n",
    "                    extracted_name = sub_root.split(\"\\\\\")[1]\n",
    "                    print(extracted_name)\n",
    "                j += 1\n",
    "               \n",
    "                \"\"\" i = 0\n",
    "                for f in tqdm(sub_files):\n",
    "                    path = os.path.join(sub_root,f)\n",
    "                    clean_path = DIR_CLEAN_DATA+dir+extracted_name/\"((some))\"+'_clean.html'\n",
    "                    if i == 2:\n",
    "                        print(clean_path)\n",
    "                        break\n",
    "                    i += 1 \"\"\"\n",
    "\n",
    "\n",
    "        \"\"\" \n",
    "        for dir in tqdm(dirs):\n",
    "            sub_DIR_RAW_DATA_PATH = os.path.join(root,dir)\n",
    "            for sub_root,sub_dirs,sub_files in os.walk(sub_DIR_RAW_DATA_PATH):\n",
    "                # foeach file in dir\n",
    "                for f in tqdm(sub_files):\n",
    "                    #index = f.split('.')[0]\n",
    "                    path = os.path.join(sub_root,f)\n",
    "                    clean_path = DIR_CLEAN_DATA+'_clean.html'\n",
    "                    cleaner = HTMLCleaner(path,clean_path)\n",
    "                    cleaner.clean_html()\n",
    "                    #cleaner.clean_tree()\n",
    "                    storer = HTMLStorer(input_file=None,html=cleaner.line)\n",
    "                    g.write(json.dumps(storer.data,ensure_ascii=False)+'\\n') \"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
